{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning using Auto Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras version:\", K.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = mnist.load_data()\n",
    "\n",
    "# reshape images to 1D\n",
    "train_images = train_images.astype('float32') / 255.\n",
    "test_images = test_images.astype('float32') / 255.\n",
    "train_images = train_images.reshape((len(train_images), 784))\n",
    "test_images = test_images.reshape((len(test_images), 784))\n",
    "\n",
    "# add noise to images\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = train_images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_images.shape) \n",
    "x_test_noisy = test_images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_images.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "train_labels = K.utils.to_categorical(train_labels, 10)\n",
    "test_labels = K.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the model\n",
    "input_img = K.layers.Input(shape=(784,))\n",
    "# encoder\n",
    "encoded = K.layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = K.layers.Dense(64, activation='relu')(encoded)\n",
    "# decoder\n",
    "decoded = K.layers.Dense(128, activation='relu')(encoded)\n",
    "decoded = K.layers.Dense(784, activation='sigmoid')(decoded)\n",
    "autoencoder = K.Model(input_img, decoded)\n",
    "encoder = K.Model(input_img, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# early stopping\n",
    "early_stopping = K.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=5,\n",
    "    verbose=1, \n",
    "    restore_best_weights=True)\n",
    "\n",
    "# autoencoder's training\n",
    "autoencoder.fit(x_train_noisy, train_images,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract hidden representations using the encoder\n",
    "encoded_train_images = encoder.predict(train_images)\n",
    "encoded_test_images = encoder.predict(test_images)\n",
    "\n",
    "# set up classifier model\n",
    "classifier_input = layers.Input(shape=(64,))\n",
    "classifier_output = layers.Dense(10, activation='softmax')(classifier_input)\n",
    "classifier = K.Model(classifier_input, classifier_output)\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training the classifier\n",
    "classifier.fit(encoded_train_images, train_labels,\n",
    "               epochs=50, \n",
    "               batch_size=256,\n",
    "               validation_split=0.2,\n",
    "               callbacks=[early_stopping])\n",
    "\n",
    "# classifier's evaluation\n",
    "test_loss, test_accuracy = classifier.evaluate(encoded_test_images, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy}, Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the reconstruction error on the test set\n",
    "mse = K.losses.MeanSquaredError()\n",
    "reconstruction_error = mse(autoencoder.predict(x_test_noisy), test_images).numpy()\n",
    "print(f'Reconstruction error: {reconstruction_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a noise image and iteratively denoise it\n",
    "noise_image = np.random.normal(loc=0, scale=1, size=(1, 784))\n",
    "noise_image = np.clip(noise_image, 0., 1.)\n",
    "\n",
    "for i in range(100):  # Number of iterations can be adjusted\n",
    "    noise_image = autoencoder.predict(noise_image)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iteration {i}\")\n",
    "\n",
    "# plot the denoised image\n",
    "plt.imshow(noise_image.reshape(28, 28), cmap='gray')\n",
    "plt.title(\"Denoised Image\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
